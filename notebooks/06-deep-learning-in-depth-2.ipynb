{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Image Classification [Part 2]**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Required Reading**\n",
    "\n",
    "- [Ian Goodfellow's Deep Learning - Chapter 1, Section 6.2, and Section 8.1](https://www.deeplearningbook.org/contents/intro.html)\n",
    "- [AlexNet Paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)\n",
    "\n",
    "**Additional Reading/Viewing**\n",
    "\n",
    "[Outstanding YouTube Series from 3 Blue 1 Brown](https://www.youtube.com/watch?v=aircAruvnKk)\n",
    "\n",
    "**Recommended** [Jupyter Theme](https://github.com/dunovank/jupyter-themes) for presenting this notebook:\n",
    "\n",
    "````\n",
    "jt -t grade3 -cellw=90% -fs=20 -tfs=20 -ofs=20\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convolutional Neural Networks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Last time, in Image Classification Part 1, we left off wondering how Yann LeCun beat our 5 layer deep network way back in 1998. \n",
    "- Here's a clip of Yann in 1993 at AT&T Bell Labs demonstrating LeNet-1, a precursor to his 1998 network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"960\"\n",
       "            height=\"540\"\n",
       "            src=\"https://www.youtube.com/embed/FwFduRA_L6Q\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x10af89048>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('FwFduRA_L6Q', width = 960, height = 540)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yann LeCun joined AT&T Bell Labs in 1988 after leaving a postdoc position on Geoff Hinton's lab at the University of Toronto. \n",
    "- LeCun's research focused on optical charecter recognition (OCR), and developed a system that was used to read 10% of all the checks in the US in the late 1990s and early 2000s. [Source](https://en.wikipedia.org/wiki/Yann_LeCun).\n",
    "- His collaborators at AT&T included Leon Bottou and [Vladimir Vapnik](https://en.wikipedia.org/wiki/Vladimir_Vapnik).\n",
    "- In 2013, Yann became the director of Facebook AI Research (FAIR). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **So how did Yann Lecun beat our 5-layer deep network way back in 1998?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The key difference between Yann's network and ours is an idea that Yann called **weight sharing** in his [1989 Publication on Handwritten Zip Code Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/birth_of_modern_cnn-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Today we call Yann's idea a Convolutional Neural Network (CNN). \n",
    "- [Goodfellow](https://www.deeplearningbook.org/contents/convnets.html) gives a nice CNN definition: \n",
    "*\"Convolutional networks are simply neural networks that use convolution in place of general matrix multiplication in at least one of their layers.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **They Should Really Be Called \"Cross Correlation Neural Networks\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/filter_animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The convolution operation is used in many areas of mathematics and engineering, we can express 2d convolution like this:\n",
    "$$\n",
    "S(i, j) = \\sum_m \\sum_n I(i-m, j-n)K(m, n)\n",
    "$$\n",
    "- Where $I$ is our input image, $K$ is kernel and S is our output. \n",
    "- Subtracting $m$ and $n$ from $i$ and $j$ has the effect of flipping our kernel $K$ makes convolution commutative. However, in Convolutional Neural Networks, we don't really care about the commutative property, and many libraries, including tensorflow implement the **cross-correlation** function instead of **convolution**:\n",
    "\n",
    "$$\n",
    "S(i, j) = \\sum_m \\sum_n I(i+m, j+n)K(m, n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 CNN Walkthrough\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's walkthrough how CNNs process input images. \n",
    "- We'll borrow some slides from [Stanford's CS 231n: Convolutional Neural Networks for Visual Recognition](https://www.youtube.com/watch?v=LxfUGhug-iQ&list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC&index=7).\n",
    "- A nice way to think about the convolutional operations we apply in neural networks is **operations on volumes**, as opposed to the operations on vectors we saw with regular neural networks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from ipywidgets import interact\n",
    "\n",
    "def slide_show(slide_num=1):     \n",
    "    display(Image('../graphics/cs_231n_cnn_slides/cs_231n_' + str(slide_num) + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ac721ee93b47689849de857d82ab0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='slide_num', max=5, min=1), Output()), _dom_classes=('wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(slide_show, slide_num = (1, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Padding + Strides\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can imagine, there are many variants of convolution used in CNNs, there's a [really great paper on this](https://arxiv.org/pdf/1603.07285.pdf). \n",
    "- Changing our padding or strides will change the size of our data as it flows through our network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; table-layout:fixed;\">\n",
    "  <tr>\n",
    "    <td><img width=\"150px\" src=\"../graphics/conv_animations/no_padding_no_strides.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"../graphics/conv_animations/arbitrary_padding_no_strides.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"../graphics/conv_animations/same_padding_no_strides.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"../graphics/conv_animations/full_padding_no_strides.gif\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>No padding, no strides</td>\n",
    "    <td>Arbitrary padding, no strides</td>\n",
    "    <td>Half padding, no strides</td>\n",
    "    <td>Full padding, no strides</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img width=\"150px\" src=\"../graphics/conv_animations/no_padding_strides.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"../graphics/conv_animations/padding_strides.gif\"></td>\n",
    "    <td><img width=\"150px\" src=\"../graphics/conv_animations/padding_strides_odd.gif\"></td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>No padding, strides</td>\n",
    "    <td>Padding, strides</td>\n",
    "    <td>Padding, strides (odd)</td>\n",
    "    <td></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 How is LeNet-5 so good?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As nicely stated the exceprt from Yann Lecun's 1989 paper above, CNNs \"allow us to express information about the geometry and topology of the task\". The arrangement of the pixels in our images is not arbitrary, and we know the lots of information can be gleaned by looking at local neighborhoods of our images (such as edge detection) - CNNs are a good for this. \n",
    "- Aside from taking advantage of the topology of images, CNNs are also **incredibly efficient**. \n",
    "- Let's have a look at LeCun's 1998 convolutional neueral network, LeNet-5, that achieves a 99.05 accuracy on mnist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/question_two-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/question_three-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, the first layer of LeNet-5 has way less parameters than our 7 layer fully connected layers. \n",
    "- **Why might this be advantageous?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Pooling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's look at one more interesting idea from LeNet-5. After each convolutional layer, Yann includes a \"subsampling\" layer. Today we call this a **pooling** layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/lenet_5_screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that after each of Yann's pooling layers, our feature maps decrease in size by a factor of 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![](../graphics/pooling-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pooling makes our networks **approximately invariant** to translations in our input. \n",
    "- This can be advantageous in problems like image classification, where the exactly location of features is less important than their general location. \n",
    "- Pooling also reduces the size of our data at it flows through our network, allowing us to effectively make our networks smaller and more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Let's Train LeNet-5!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll implement a modern version of LeNet-5, with a few changes from Yann's original implementation:\n",
    "    - Activation functions immediately follow conv layers, not pooling layers. \n",
    "    - Our pooling layers don't have learnable parameters, unlike LeCun's sub-sampling layers \n",
    "    - We'll using a cross entropy cost function, LeNet used radial basis functions \n",
    "    - We'll using the Adam optimizer, LeCun used gradient descent with a variable learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll borrow this method from Jeremy Howard's great [neural network tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html), that will allow us to use view to rehshape our tensor after our convolutional layers.\n",
    "- Apparently doing this is a bit contreversial, the PyTorch authors would prefer you create your models using classes, as we saw in our introduction_to_pytorch notebook, where the fastai preferece is to use nn.Sequential to create models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/lenet_5_screenshot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modern Version of LeNet-5 in Pytorch\n",
    "model = nn.Sequential(nn.Conv2d(1, 6, kernel_size = 5), nn.Tanh(), \n",
    "                     nn.AvgPool2d(2), \n",
    "                     nn.Conv2d(6, 16 , kernel_size = 5), nn.Tanh(), \n",
    "                     nn.AvgPool2d(2), \n",
    "                     Lambda(lambda x: x.view(x.size(0),-1)), \n",
    "                     nn.Linear(256, 120), nn.Tanh(),\n",
    "                     nn.Linear(120, 84), nn.Tanh(),\n",
    "                     nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A really valuable/important step is comparing this pytorch code line by line with the architecture we're implementing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from matplotlib.pyplot import *\n",
    "import pickle, gzip\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = Path(\"../data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To use `Conv2d` in Pytorch, we need to reshape our data into tensors of shape (batch_size, color_channels, image_height, image_width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 1, 28, 28)\n",
    "x_valid = x_valid.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '9')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Double check tha tour reshape is doing what we think it is!\n",
    "imshow(x_train[600, 0, :, :])\n",
    "title(y_train[600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataloaders\n",
    "train_ds = TensorDataset(torch.tensor(x_train, dtype = torch.float), torch.tensor(y_train, dtype = torch.long))\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle = True, num_workers = 4, drop_last = True)\n",
    "\n",
    "valid_ds = TensorDataset(torch.tensor(x_valid, dtype = torch.float), torch.tensor(y_valid, dtype = torch.long))\n",
    "valid_dl = DataLoader(valid_ds, batch_size=256, shuffle = True, num_workers = 4, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanh() torch.Size([64, 6, 24, 24])\n",
      "AvgPool2d(kernel_size=2, stride=2, padding=0) torch.Size([64, 6, 24, 24])\n",
      "Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) torch.Size([64, 6, 12, 12])\n",
      "Tanh() torch.Size([64, 16, 8, 8])\n",
      "AvgPool2d(kernel_size=2, stride=2, padding=0) torch.Size([64, 16, 8, 8])\n",
      "Lambda() torch.Size([64, 16, 4, 4])\n",
      "Linear(in_features=256, out_features=120, bias=True) torch.Size([64, 256])\n",
      "Tanh() torch.Size([64, 120])\n",
      "Linear(in_features=120, out_features=84, bias=True) torch.Size([64, 120])\n",
      "Tanh() torch.Size([64, 84])\n",
      "Linear(in_features=84, out_features=10, bias=True) torch.Size([64, 84])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(train_dl))\n",
    "for i in range(1, len(model)):\n",
    "    a = model[:i](x)\n",
    "    print(model[i], a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, training loss = 0.261, valid accuracy = 0.941\n",
      "Epoch: 2, training loss = 0.195, valid accuracy = 0.973\n",
      "Epoch: 3, training loss = 0.152, valid accuracy = 0.961\n",
      "Epoch: 4, training loss = 0.077, valid accuracy = 0.953\n",
      "Epoch: 5, training loss = 0.059, valid accuracy = 0.977\n",
      "Epoch: 6, training loss = 0.071, valid accuracy = 0.969\n",
      "Epoch: 7, training loss = 0.024, valid accuracy = 0.984\n",
      "Epoch: 8, training loss = 0.014, valid accuracy = 0.98\n",
      "Epoch: 9, training loss = 0.013, valid accuracy = 0.984\n",
      "Epoch: 10, training loss = 0.048, valid accuracy = 0.953\n",
      "Epoch: 11, training loss = 0.03, valid accuracy = 0.992\n",
      "Epoch: 12, training loss = 0.004, valid accuracy = 0.988\n",
      "Epoch: 13, training loss = 0.004, valid accuracy = 0.992\n",
      "Epoch: 14, training loss = 0.003, valid accuracy = 0.992\n",
      "Epoch: 15, training loss = 0.031, valid accuracy = 0.996\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15; lr = 1e-1; accuracies_cross_entropy = [] #We can use a higher learning rate with cross entroy loss. \n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "for i in range(num_epochs):\n",
    "    for x, y in train_dl:\n",
    "        yhat = model(x)\n",
    "        loss = F.cross_entropy(yhat, y) #Takes care of softmax and one hot encoding for us!\n",
    "        loss.backward() \n",
    "        opt.step(); opt.zero_grad();\n",
    "    \n",
    "    #Check validation loss and accuracy at the end of each epoch:\n",
    "    model.eval() #Put in evaluation mode!\n",
    "    with torch.no_grad():\n",
    "        x, y = next(iter(valid_dl)) #Just measure on one minibatch\n",
    "        yhat = model(x)\n",
    "        max_values, max_indices = torch.max(yhat, dim=1)\n",
    "        accuracy = (max_indices.eq(y).sum().float()/len(y)).item()\n",
    "        accuracies_cross_entropy.append(accuracy)\n",
    "        print('Epoch: ' + str(i+1) + ', training loss = ' + str(round(loss.item(), 3)) + \\\n",
    "              ', valid accuracy = ' + str(round(accuracy, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9872999787330627"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Measure Accuracy on complete validation set for better accuracy estimate:\n",
    "x = torch.tensor(x_valid, dtype = torch.float)\n",
    "y = torch.tensor(y_valid, dtype = torch.long)\n",
    "yhat = model(x)\n",
    "max_values, max_indices = torch.max(yhat, dim=1)\n",
    "accuracy = (max_indices.eq(y).sum().float()/len(y)).item()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We've acheived a ~99% test set accuracy with our LeNet-5 implementation!\n",
    "- We did this be leveraging something we knew about images: **That the relative location of our pixels mater**, and that we can achieve very good performance by sliding the same convolutional kernel across our whole image. \n",
    "- If you're interested in the specific filters that LeNet-5 learns, Yann has some nice [visualizations](http://yann.lecun.com/exdb/lenet/index.html) of LeNet-5 in action on this website. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Why Didn't Deep Learning Take Off in the Early 2000s?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we'll see, Yann's deep neural network architecture, LeNet-5 is remarkably similar to the models we use today. \n",
    "- However, as you may know, **deep learning** didn't really take off until ~2012. \n",
    "- What took so long? \n",
    "- How are modern deep learning models different than LeNet-5?\n",
    "- In the next section, we'll discuss a bit of history, and then try to answer these questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ImageNet and AlexNet\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/fei_fei_li-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Beginning around 2006, Fei Fei Li, then a new professor at the University of Illinois Urbana-Champaign, began working on building the largest labeled image dataset ever constructed. [Great Article on Fei Fei Li and ImageNet](https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/).\n",
    "- She chose to use the [WordNet lexical database](https://en.wikipedia.org/wiki/WordNet) for her class labels, and to focus on finding images for each \"synset\" in Wordnet. \n",
    "- Li first tried hiring undergraduate students to perform annotation, but quickly found that this appraoch simple would not achieve the scale she needed, and instead used Amazon Mechanical Turk. \n",
    "- ImageNet was first published in 2009, and quickly developed into a public computer vision competition, the ImageNet Large Scale Visual Recognition Competition (ILSVRC). \n",
    "- ILSVRC used a subset of 1000 imaget classes, and included ~1.2M training images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1280\"\n",
       "            height=\"720\"\n",
       "            src=\"https://www.youtube.com/embed/WO_mP-HPH4M\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x13963abe0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('WO_mP-HPH4M', width = 1280, height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, perhaps not surprisingly, ILSVRC turned out to be quite difficult. \n",
    "- The best performance achieved in 2010 was a top-5 test set error rate of **28.2%**. Top-5 means that the correct answer was one of the top five answers given by the network. \n",
    "- In 2011, the top-5 error rate dropped to **25.8%**, [achieved by a team from Xerox](http://image-net.org/challenges/LSVRC/2011/results) using SIFT and Fisher Vectors (FVs).\n",
    "- And then...this happened:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Hinton et al Make Neural Networks Sexy Again...Again\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/hinton_krizhevinsky-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SuperVision, a team from the University of Toronto, led by Geoff Hinton (Remember Him?) **reduced the top-5 test set error by around 40%, down to 15.4%.**\n",
    "- The model they used is today often called \"AlexNet\" after Alex Krizhevsky\n",
    "- So, how did Hinton's team acheive such a huge increase in performance? What type of magic was afoot? \n",
    "- Let's have a closer look at the [AlexNet Paper](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n",
    "- Hinton's team used a deep neural network, not all that different from LeNet-5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/alexnet_paper_screenshots/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This figure drives be crazy becuase the top part is cropped off in the original paper, one of these days I'm going to make a non-cropped version. \n",
    "- There's also apparently an error in the paper - the input image size should be 227x227. \n",
    "- Let's take some time to talk throught the **Alexnet** architecture. \n",
    "- First, this figure shows 2 copies of most layers - **why?**\n",
    "- Next, why is our output of dimenion 1000? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pretrained Alexnet in Pytorch\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alright, let's walk through AlexNet in detail.\n",
    "- We'll use a simplified AlexNet, where we merge Alex's two GPU pipelines into one.\n",
    "- We can grab a pretrained version of Alexnet using [torchvision](https://pytorch.org/docs/stable/torchvision/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c658c53ff437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0malexnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "alexnet = models.alexnet(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.eval() #Put Model into evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To get a feeling for what exactly alexnet if doing, let's walkthrough the network step by step. \n",
    "- There's a couple new concepts here, ReLU activation functions and Dropout, we'll discuss these as we get to them. \n",
    "- Let's grab an example image to pass through our network.\n",
    "- We'll use the Python Image Library (PIL) to import our image, PIL offers some nice compatabilities with pytorch and fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open('../data_sample/golf_ball.JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To actually pass our image into our network, we need to do a little preprocessing, including converting it into a pytorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "tfms = transforms.Compose([transforms.Resize((224, 224)), #Resize to standard alexnet size\n",
    "                                transforms.ToTensor(), #Convert to tensor\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], #Normalize using imagenet stats \n",
    "                                                     std=[0.229, 0.224, 0.225])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_tensor = tfms(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_tensor.shape #Notice that our color channels are now first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick visualization to see what we've got!\n",
    "fig = figure(0, (6,6))\n",
    "imshow(im_tensor.numpy()[0,:,:])\n",
    "title('Red color channel of reshaped tensor');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before processing our image, we have to make one more minor adjustment. \n",
    "- Our network expects a minibatch of images of dimension (batch_size, color_channels, height, width). \n",
    "- Since we only have one image, we need to expand the dimension of our tensor from 3 to 4. \n",
    "- We can use this little trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_tensor.shape, im_tensor[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can finally pass our image into alexnet!\n",
    "with torch.no_grad():\n",
    "    yhat = alexnet(im_tensor[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(0, (18, 6))\n",
    "plot(yhat.detach().numpy().ravel())\n",
    "grid(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why is the dimension of our alexnet output (1, 1000)?\n",
    "- What do these numbers **mean**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you may have guessed, we have one prediction for each of the imagenet (ILSVRC 2012) class. \n",
    "- Now, let's look at the scale of our prediction values - they range from -10 to around 25 - why is this?\n",
    "- As we discussed in image classification part 1, classification models like alexnet are generally trained using a softmax output layer and a cross-entropy loss function. \n",
    "- The softmax function is generally part of the loss function, we can see that it hasn't been included in our pretrained alexnet. \n",
    "- If we add back in the softmax function, our outputs will be a bit easier to understand\n",
    "- Further, we can (under certain assumptions) interpret the softmax outputs as the models probability of a certian label, given the image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_softmax = nn.Softmax(dim =1)(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(0, (18, 6))\n",
    "plot(yhat_softmax.detach().numpy().ravel())\n",
    "grid(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That makes more sense! As you can see, after applying our softmax, our model is stronly predicting one class over the rest. \n",
    "- Let's see which class it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To figure out which label our class index corresponds to, we need an imagenet index to label conversion:\n",
    "with open(\"../data_sample/imagenet_labels.txt\") as f:\n",
    "    idx2label = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label[torch.argmax(yhat).item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alright, so as you can see, our pretrained alexnet model is making a pretty reasonable prediction!\n",
    "- Now, in the interesting of really understanding what's going on, let's spend a little time walkthrough our alexnet model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Alexnet \"Conv 1\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our model is divided into 3 sections: features, avgpool, and classifier. \n",
    "- We can directly access a given layer like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is our first convolutional layer. As we can see, it's using a kernel size of (11x11). \n",
    "- Why is our number of input filters 3?\n",
    "- Let's have a look at our actual weight values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = alexnet.features[0].weight\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(0, (16, 16))\n",
    "for i in range(w.shape[0]):\n",
    "    fig.add_subplot(8, 8, i+1)\n",
    "    filt = np.moveaxis(w[i].detach().numpy().copy(), (0, 1, 2), (2, 0, 1))\n",
    "    filt -= filt.min(); filt /= filt.max(); #Rescale between 0 and 1 for imshow\n",
    "    imshow(filt); axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see, our alexnet model learned some really interesting filter structures from training on imagenet!\n",
    "- What types of patterns would these filters respond to?\n",
    "- Some of these should remind you of the edge detectors we say earlier in the course!\n",
    "- We also see what appear to be \"blob detectors\" and maybe \"texture detectors\".\n",
    "- Can you believe this shit actually works!?\n",
    "- Now let's see what actually happens to our image in this first convolutional layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    activations = alexnet.features[0](im_tensor[None]) #Pass image through first layer\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = figure(0, (20, 20))\n",
    "for i in range(64): #activations.shape[1]):\n",
    "    fig.add_subplot(8, 8, i+1)\n",
    "    feature_map = activations[0, i, :, :].detach().numpy()\n",
    "    imshow(feature_map); axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These are the 64 channels our image is processed \"into\" in our first convoluational layer. \n",
    "- Notice that our filters are responding to different parts of the images. \n",
    "- There's a [really cool tool](https://www.youtube.com/watch?time_continue=31&v=AgkfIQ4IGaM) from Yosinski et al. for visualizing these activations through alexnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ReLU\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ok, so we now hopefully have some sense for what our first convolutaional layer has learned to do.\n",
    "- The AlexNet team used an activation function that had not been widely used in neural networks before - Rectified Linear Units (ReLU). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.features[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/relu_activations-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [Goodfellow section 6.3.1](https://www.deeplearningbook.org/contents/mlp.html): \n",
    "\n",
    ">\"These units are easy to optimize because they are so similar to linear units. The only diﬀerence between a linear unit and a rectiﬁed linear unit is that a rectiﬁed linear unit outputs zero across half its domain. This makes the derivatives through a rectiﬁed linear unit remain large whenever the unit is active. The gradients are not only large but also consistent. The second derivative of the rectifying operation is 0 almost everywhere, and the derivative of the rectifying operation is 1 everywhere that the unit is active.\"\n",
    "\n",
    "- Let's have a look at what our artivation funciton does to our data as it moves through our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    activations_1 = alexnet.features[0](im_tensor[None]) #Pass image through first layer\n",
    "    activations_2 = alexnet.features[:2](im_tensor[None]) #Pass image through first two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(0, (20, 10))\n",
    "for i in range(4): #activations.shape[1]):\n",
    "    fig.add_subplot(2, 4, i+1)\n",
    "    feature_map = activations_1[0, i, :, :].detach().numpy()\n",
    "    imshow(feature_map); axis('off'); colorbar(); title('Before RelU')\n",
    "\n",
    "    fig.add_subplot(2, 4, 4+i+1)\n",
    "    feature_map = activations_2[0, i, :, :].detach().numpy()\n",
    "    imshow(feature_map); axis('off'); colorbar(); title('After RelU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see, ReLU \"clips\" everything below zero to zero, and leaves the positive numbers alone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 More Convs and ReLUs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One remarkable feature of deep learning is how consistent the operations are as we move through the network. \n",
    "- As you can see, we follow a very similar pattern of convolutional layers followed by activation layers as we move through the network.\n",
    "- More modern architectures like ResNet are even more consistent from layer to layer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's have a look at the output after 2 convolutions and 2 max pools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    activations = alexnet.features[:6](im_tensor[None]) #Pass image through first layer\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(0, (24, 12))\n",
    "for i in range(192): #activations.shape[1]):\n",
    "    fig.add_subplot(10, 20, i+1)\n",
    "    feature_map = activations[0, i, :, :].detach().numpy()\n",
    "    #print(feature_map.min(), feature_map.max())\n",
    "    imshow(feature_map, vmin = 0, vmax = 20); axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now after 4 convolutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    activations = alexnet.features[:10](im_tensor[None]) #Pass image through first layer\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(0, (24, 24))\n",
    "for i in range(256): #activations.shape[1]):\n",
    "    fig.add_subplot(16, 16, i+1)\n",
    "    feature_map = activations[0, i, :, :].detach().numpy()\n",
    "    imshow(feature_map, vmin = 0, vmax = 20); axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And finally after the 5th convolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    activations = alexnet.features(im_tensor[None]) #Pass image through first layer\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(0, (24, 24))\n",
    "for i in range(256): #activations.shape[1]):\n",
    "    fig.add_subplot(16, 16, i+1)\n",
    "    feature_map = activations[0, i, :, :].detach().numpy()\n",
    "    imshow(feature_map, vmin = 0, vmax = 20); axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that are activations become more sparse the deeper we go into our network.\n",
    "- There's some really cool papers/tools/research that use visualization like these to gain insight into what exactly these layers are computing. \n",
    "- Interestingly, some of these deeper layers learn recognizable concepts, such as faces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('AgkfIQ4IGaM', width = 960, height = 540)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Adaptive Pooling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, we hopefully have a sense for how what the convolutional layers of alexnet are doing. \n",
    "- After passing through the final convolutional layer, we're left with a tensor of dimension (1x256x6x6):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    activations = alexnet.features(im_tensor[None]) #Pass image through first layer\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that after the convolutional layers in AlexNet, the pretrianed pytorch version includes a layer that was not part of the original architecture: `AdaptiveAvgPool2d(output_size=(6, 6))`. \n",
    "- Adaptive Average Pooling is a really convenient layer to have - unlike `nn.MaxPool2d`, where we pass in the strid and padding of our pooling filter, `nn.AdaptiveAvgPool2d` allows us to pass in the **dimension of the tensor we want out**. \n",
    "- So regardless of the dimension of the tensor that is passed in to `AdaptiveAvgPool2d(output_size=(6, 6))`, the output will be of size (batch_size, color_channels, 6, 6). \n",
    "- You may have noticed that our output here is *already* 6x6, so the `AdaptiveAvgPool2d` doesn't actually do anything. \n",
    "- The reason it's here it to allow us to pass in input images different from those the network was trained on. \n",
    "- If we change our input image size, the output of the final convolutional layer will change accordingly, and if we don't do adaptive average pooling at the end, we'll end up with tensors of different size.\n",
    "- This is problematic when our unrolled tensor meets our first linear (also known as fully connected) layer, because the input dimension is hard coded to 9216. \n",
    "- In short, adaptive average pooling allows us to change input image size without breaking our CNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_pooled = alexnet.avgpool(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(activations_pooled - activations).abs().sum() #No change!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_pooled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, before we can pass our tensor into our linear layers, we need to reshape or \"unravel\" it.\n",
    "- We can do this using the torch `view` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_pooled = activations_pooled.view(-1, 256*6*6)\n",
    "activations_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Dropout\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, before we pass our tensor through our linear layers, notice that our tensorf will first go through `Dropout(p=0.5)`. \n",
    "- This is another key innovation from the AlexNet paper, and is a very simple and effective way to reduce overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/dropout-01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_dropout = nn.Dropout(0.5)(activations_pooled)\n",
    "print(activations_pooled[0, :25])\n",
    "print(activations_dropout[0, :25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(0, (18, 6))\n",
    "plot(activations_pooled[0, :30].detach().numpy().ravel(), marker = 'x')\n",
    "plot(activations_dropout[0, :30].detach().numpy().ravel()/2, marker = 'x'); \n",
    "grid(1); legend(['Before Dropout', 'After Dropout'], fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dropout idea is really simple - we randomly \"turn off\" neurons. Neurons that are off do not participate in the forward pass or in backpropogation. \n",
    "- The idea here is that this forces the network to learn more robust representation that do not rely on other neurons always \"being on\". \n",
    "- Deep Nets are very prone to overfitting, and dropout is a cheap and easy way to reduce this. \n",
    "- At test time, dropout is turned off, generally resulting in a nice performance boost - this is one of the reasons we run `model.eval()` before testing out model - this turns off dropout.\n",
    "- Finally, when dropout is implemented, most libraries will boost the remaining neurons to keep the overall mean output relatively consistent for a given layer. You can see in the plot above I hade to divide the dropped out tensor values by 2 (this is 1/dropout rate) to make the 2 outputs line up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Fully Connected/Linear Layers\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet.classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All that's left now is to pass our tensor through the 3 linear/fully connected layers at the end of alexnet. \n",
    "- In the time since the AlexNet publication, fully connected layers like this have fallen out of favor for computer vision problems - it turns out we can mostly get away wiht just convolutional layers!\n",
    "- Note that most of our weights are in the convolutional layers. \n",
    "- What exactly these layers are doing isn's as easy to make intuitive sense of, relative to the convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = alexnet.classifier[1].weight\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(0, (18, 8))\n",
    "imshow(w.detach()); colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here's the first set of fully connected weights, all 37,748,736 of them!\n",
    "- From this perspective, it's not so obvoius what they're doing. The thing to know for now is that just our unravelled tensor of length 9216 is multiplied by this huge matrix, and the result is passed on to the next  layer. \n",
    "- Let's go ahead and pass our pooled and unraveled activations through all our linear layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = alexnet.classifier(activations_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2label[torch.argmax(yhat).item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alright, we made it all the way through!\n",
    "- Note that we skipped the softmax step this time. \n",
    "- Since softmax is a **monotonic** function of it's inputs, we don't actually need to apply softmax before taking the argmax. \n",
    "- Softmax is nice to have when we want probability estimates that nicely add to one, and can give us more interpretable results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 AlexNet Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/alexnet_results-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Transfer Learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One particularly exciting thing about the AlexNet results is how adaptable deep models are to other computer vision problems. \n",
    "- [Razavian et. al.](https://arxiv.org/pdf/1403.6382.pdf) and [Donahue et. al.](https://arxiv.org/pdf/1310.1531.pdf) show that \"off-the-shelf\" CNNs plus a simple linear classifier outperform existing state of the art accross many computer vision tasks. \n",
    "- Since the AlexNet publication, researchers have found more and more applications that can be solved using a pretrained \"CNN Backbone\" like alexnet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/transfer_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There's one more improtant idea from the AlexNet paper we need to discuss.\n",
    "- This idea is not unique to this paper, but Geoff Hinton and his collaborators did play a big role in popularizing this technique. \n",
    "- Data augmentation is a great way to make our dataset appear larger than it actually is. \n",
    "- By implementing **label preserving transforms** on our images such as crops, shifts, and small color changes, we can reduce overfitting. \n",
    "- See [Goodfellow 7.4](https://www.deeplearningbook.org/contents/regularization.html) for more details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/data_augmentation-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's have a look at how we can augment our data in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "im = Image.open('../data_sample/golf_ball.JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "tfms = transforms.Compose([transforms.Resize(256),\n",
    "                           transforms.RandomRotation(degrees = 5),\n",
    "                           transforms.RandomCrop((224, 224)), \n",
    "                           transforms.RandomHorizontalFlip(), \n",
    "                           transforms.ColorJitter(0.1, 0.1, 0.1, 0.1)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = figure(0, (20, 8))\n",
    "for i in range(10):\n",
    "    im_aug = tfms(im)\n",
    "    fig.add_subplot(2, 5, i+1)\n",
    "    imshow(np.asarray(im_aug)); axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using this transform code, we can perform augmentation at trainig time, effectively making it so that our network never sees exactly the same image twice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../graphics/spacer_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A Little Historical Perspective on the Rise of Deep Learning\n",
    "---\n",
    "\n",
    "![](../graphics/lenet_vs_alexnet-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References/Assumptions**\n",
    "- Slide inspired from min 38 of [great talk from Andrej Kerpathy](https://youtu.be/f6ZKaBm3cXU).\n",
    "- 267 MHz Pentium II single core processor, 1 floating point operation per clock cycle (shoot me an email if you have a better estimate. A couple somewhat relevant sources: [1](https://www.alternatewars.com/BBOW/Computing/Computing_Power.htm) [2](https://projects.ncsu.edu/hpc/Courses/1arch.html)\n",
    "- GTX 580 GPU FLOPS from [here](https://www.techpowerup.com/gpu-specs/geforce-gtx-580.c270).\n",
    "- Back of the envelope LeNet math: `5*5*1*28*28*6*2 + 5*5*6*10*10*16*2 + 16*5*5*120*2 + 120*84*2 + 84*2`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What took so long?**\n",
    "- As you can see above, remarkably little changed algorithmically between 1998 and 2012. \n",
    "- ReLU and dropout are helpful, but not critical for deep learning. \n",
    "- And as [Andrej Kerpathy](https://youtu.be/f6ZKaBm3cXU) points out, these two changes both just involve setting something to zero! :)\n",
    "- In fact you could argue that, **everything we needed for deep learning was in place and known in 1998!**\n",
    "- Goodfellow has some interesting things to say about this: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\"At this point [2006], deep networks were generally believed to be very diﬃcult to train. We now know that algorithms that have existed since the 1980s work quitewell, but this was not apparent circa 2006. The issue is perhaps simply that these algorithms were too computationally costly to allow much experimentation withthe hardware available at the time.\"*\n",
    "- Deep Learning, Ian Goodfellow, Section 1.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\"Convolutional nets were some of the ﬁrst working deep networks trained with back-propagation. It is not entirely clear why convolutional networks succeeded when general back-propagation networks were considered to have failed. It may simply be that convolutional networks were more computationally eﬃcient than fully connected networks, so it was easier to run multiple experiments with them and tune their implementation and hyperparameters. Larger networks also seem to be easier to train. With modern hardware, large fully connected networks appear to perform reasonably on many tasks, even when using datasets that were available and activation functions that were popular during the times when fully connected networks were believed not to work well. It may be that the primary barriers to the success of neural networks were psychological (practitioners did not expect neural networks to work, so they did not make a serious eﬀort to use neural networks). Whatever the case, it is fortunate that convolutional networksperformed well decades ago. In many ways, they carried the torch for the rest ofdeep learning and paved the way to the acceptance of neural networks in general.\" \n",
    "- Deep Learning, Ian Goodfellow, Section 9.11"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
